<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.0">Jekyll</generator><link href="https://sv-97.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://sv-97.github.io/" rel="alternate" type="text/html" /><updated>2023-02-04T20:52:43+00:00</updated><id>https://sv-97.github.io/feed.xml</id><title type="html">Stefan Volz</title><subtitle>Persönliche Website</subtitle><author><name>Stefan Volz</name><email>volzstefan97@googlemail.com</email></author><entry><title type="html">Solving advent of code 2021’s day 8 with linear algebra</title><link href="https://sv-97.github.io/math/linear-algebra/aoc/aoc21-8/" rel="alternate" type="text/html" title="Solving advent of code 2021’s day 8 with linear algebra" /><published>2021-12-08T00:00:00+00:00</published><updated>2021-12-08T00:00:00+00:00</updated><id>https://sv-97.github.io/math/linear-algebra/aoc/aoc21-8</id><content type="html" xml:base="https://sv-97.github.io/math/linear-algebra/aoc/aoc21-8/">&lt;p&gt;&lt;a href=&quot;https://adventofcode.com/2021/day/8&quot;&gt;Day 8&lt;/a&gt; of &lt;a href=&quot;https://adventofcode.com/2021&quot;&gt;Advent of code 2021&lt;/a&gt; was a problem that became quite easily solveable by using linear algebra.&lt;/p&gt;

&lt;style&gt; .pdf-embed-wrap-04d5856d-79c6-4483-8fea-e6001a0bda40 { display:flex; flex-direction: column; width: 100%; height: 650px; } .pdf-embed-container-04d5856d-79c6-4483-8fea-e6001a0bda40 { height: 100%; } .pdf-link-04d5856d-79c6-4483-8fea-e6001a0bda40 { background-color: white; text-align: center; border-style: solid; } .pdf-embed-container-04d5856d-79c6-4483-8fea-e6001a0bda40 iframe { width: 100%; height: 100%; } &lt;/style&gt;
&lt;div class=&quot;pdf-embed-wrap-04d5856d-79c6-4483-8fea-e6001a0bda40&quot;&gt; &lt;div class=&quot;pdf-link-04d5856d-79c6-4483-8fea-e6001a0bda40&quot;&gt; &lt;a href=&quot;/assets/pdfs/2021-12-08-aoc21-8/aoc21-8.pdf&quot; target=&quot;_blank&quot;&gt;View PDF&lt;/a&gt; &lt;/div&gt; &lt;div class=&quot;pdf-embed-container-04d5856d-79c6-4483-8fea-e6001a0bda40&quot;&gt; &lt;iframe src=&quot;/assets/pdfs/2021-12-08-aoc21-8/aoc21-8.pdf&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Stefan Volz</name><email>volzstefan97@googlemail.com</email></author><category term="math" /><category term="linear-algebra" /><category term="aoc" /><summary type="html">Day 8 of Advent of code 2021 was a problem that became quite easily solveable by using linear algebra.</summary></entry><entry><title type="html">Rechtfertigung für Gramsche Determinante in Definition des k-Flächeninhalts</title><link href="https://sv-97.github.io/math/differential-geometry/analysis/k-surfaces/" rel="alternate" type="text/html" title="Rechtfertigung für Gramsche Determinante in Definition des k-Flächeninhalts" /><published>2021-09-27T00:00:00+00:00</published><updated>2021-09-27T00:00:00+00:00</updated><id>https://sv-97.github.io/math/differential-geometry/analysis/k-surfaces</id><content type="html" xml:base="https://sv-97.github.io/math/differential-geometry/analysis/k-surfaces/">&lt;p&gt;In der Definition des k-Volumens einer k-Fläche im R^n taucht die Gramsche Determinante der Parametrisierung auf. Wir wollen dies intuitiv begründen.&lt;/p&gt;

&lt;style&gt; .pdf-embed-wrap-e4b3f9ae-7fd9-4288-b0cf-dca0c50b8645 { display:flex; flex-direction: column; width: 100%; height: 650px; } .pdf-embed-container-e4b3f9ae-7fd9-4288-b0cf-dca0c50b8645 { height: 100%; } .pdf-link-e4b3f9ae-7fd9-4288-b0cf-dca0c50b8645 { background-color: white; text-align: center; border-style: solid; } .pdf-embed-container-e4b3f9ae-7fd9-4288-b0cf-dca0c50b8645 iframe { width: 100%; height: 100%; } &lt;/style&gt;
&lt;div class=&quot;pdf-embed-wrap-e4b3f9ae-7fd9-4288-b0cf-dca0c50b8645&quot;&gt; &lt;div class=&quot;pdf-link-e4b3f9ae-7fd9-4288-b0cf-dca0c50b8645&quot;&gt; &lt;a href=&quot;/assets/pdfs/2021-09-27-k-surfaces/k_flächeninhalt.pdf&quot; target=&quot;_blank&quot;&gt;View PDF&lt;/a&gt; &lt;/div&gt; &lt;div class=&quot;pdf-embed-container-e4b3f9ae-7fd9-4288-b0cf-dca0c50b8645&quot;&gt; &lt;iframe src=&quot;/assets/pdfs/2021-09-27-k-surfaces/k_flächeninhalt.pdf&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Stefan Volz</name><email>volzstefan97@googlemail.com</email></author><category term="math" /><category term="differential-geometry" /><category term="analysis" /><summary type="html">In der Definition des k-Volumens einer k-Fläche im R^n taucht die Gramsche Determinante der Parametrisierung auf. Wir wollen dies intuitiv begründen.</summary></entry><entry><title type="html">Seminararbeit: Innere Geometrie der Flächen</title><link href="https://sv-97.github.io/seminar-innere-geometrie" rel="alternate" type="text/html" title="Seminararbeit: Innere Geometrie der Flächen" /><published>2021-09-13T00:00:00+00:00</published><updated>2021-09-13T00:00:00+00:00</updated><id>https://sv-97.github.io/inner-geometry</id><content type="html" xml:base="https://sv-97.github.io/seminar-innere-geometrie">&lt;p&gt;Im Wintersemester 2021/22 hielt ich im Rahmen meines Studiums der Technomathematik einen Vortrag zum Thema &lt;em&gt;Innere Geometrie der Flächen&lt;/em&gt;.
Das zugehörige Skript kann &lt;a href=&quot;/assets/pdfs/2021-09-13-inner-geometry/skript.pdf&quot;&gt;hier&lt;/a&gt; und die Folien &lt;a href=&quot;/assets/pdfs/2021-09-13-inner-geometry/slides.pdf&quot;&gt;hier&lt;/a&gt; heruntergeladen werden.&lt;/p&gt;

&lt;h2 id=&quot;seminararbeit&quot;&gt;Seminararbeit&lt;/h2&gt;

&lt;style&gt; .pdf-embed-wrap-18a7f7ba-7de4-4f4c-9acd-541d37c449fd { display:flex; flex-direction: column; width: 100%; height: 650px; } .pdf-embed-container-18a7f7ba-7de4-4f4c-9acd-541d37c449fd { height: 100%; } .pdf-link-18a7f7ba-7de4-4f4c-9acd-541d37c449fd { background-color: white; text-align: center; border-style: solid; } .pdf-embed-container-18a7f7ba-7de4-4f4c-9acd-541d37c449fd iframe { width: 100%; height: 100%; } &lt;/style&gt;
&lt;div class=&quot;pdf-embed-wrap-18a7f7ba-7de4-4f4c-9acd-541d37c449fd&quot;&gt; &lt;div class=&quot;pdf-link-18a7f7ba-7de4-4f4c-9acd-541d37c449fd&quot;&gt; &lt;a href=&quot;/assets/pdfs/2021-09-13-inner-geometry/skript.pdf&quot; target=&quot;_blank&quot;&gt;View PDF&lt;/a&gt; &lt;/div&gt; &lt;div class=&quot;pdf-embed-container-18a7f7ba-7de4-4f4c-9acd-541d37c449fd&quot;&gt; &lt;iframe src=&quot;/assets/pdfs/2021-09-13-inner-geometry/skript.pdf&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt; &lt;/div&gt; &lt;/div&gt;

&lt;h2 id=&quot;folien&quot;&gt;Folien&lt;/h2&gt;

&lt;style&gt; .pdf-embed-wrap-ec74d17b-34d9-472d-ab77-50ec61a41fb1 { display:flex; flex-direction: column; width: 100%; height: 650px; } .pdf-embed-container-ec74d17b-34d9-472d-ab77-50ec61a41fb1 { height: 100%; } .pdf-link-ec74d17b-34d9-472d-ab77-50ec61a41fb1 { background-color: white; text-align: center; border-style: solid; } .pdf-embed-container-ec74d17b-34d9-472d-ab77-50ec61a41fb1 iframe { width: 100%; height: 100%; } &lt;/style&gt;
&lt;div class=&quot;pdf-embed-wrap-ec74d17b-34d9-472d-ab77-50ec61a41fb1&quot;&gt; &lt;div class=&quot;pdf-link-ec74d17b-34d9-472d-ab77-50ec61a41fb1&quot;&gt; &lt;a href=&quot;/assets/pdfs/2021-09-13-inner-geometry/slides.pdf&quot; target=&quot;_blank&quot;&gt;View PDF&lt;/a&gt; &lt;/div&gt; &lt;div class=&quot;pdf-embed-container-ec74d17b-34d9-472d-ab77-50ec61a41fb1&quot;&gt; &lt;iframe src=&quot;/assets/pdfs/2021-09-13-inner-geometry/slides.pdf&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Stefan Volz</name><email>volzstefan97@googlemail.com</email></author><category term="math" /><category term="differential-geometry" /><summary type="html">Im Wintersemester 2021/22 hielt ich im Rahmen meines Studiums der Technomathematik einen Vortrag zum Thema Innere Geometrie der Flächen. Das zugehörige Skript kann hier und die Folien hier heruntergeladen werden.</summary></entry><entry><title type="html">Generierende Funktionen und Integraltransformationen</title><link href="https://sv-97.github.io/math/generating-functions/generating-functions-integral-transforms/" rel="alternate" type="text/html" title="Generierende Funktionen und Integraltransformationen" /><published>2021-05-11T00:00:00+00:00</published><updated>2021-05-11T00:00:00+00:00</updated><id>https://sv-97.github.io/math/generating-functions/generating-functions-integral-transforms</id><content type="html" xml:base="https://sv-97.github.io/math/generating-functions/generating-functions-integral-transforms/">&lt;p&gt;Ich hatte schon länger eine Korrespondenz zwischen Differentialgleichungen und Rekurrenzgleichungen vermutet. Tatsächlich lassen sich die für Differentialgleichungen wichtigen Integraltransformationen als stetige generierende Funktionen auffassen. Diesen Zusammenhang erläutere ich &lt;a href=&quot;/assets/pdfs/2021-05-11-generating-functions-integral-transforms/paper.pdf&quot;&gt;hier&lt;/a&gt; näher.&lt;/p&gt;

&lt;style&gt; .pdf-embed-wrap-530a5384-04f8-47c2-a9cc-b72807775bec { display:flex; flex-direction: column; width: 100%; height: 650px; } .pdf-embed-container-530a5384-04f8-47c2-a9cc-b72807775bec { height: 100%; } .pdf-link-530a5384-04f8-47c2-a9cc-b72807775bec { background-color: white; text-align: center; border-style: solid; } .pdf-embed-container-530a5384-04f8-47c2-a9cc-b72807775bec iframe { width: 100%; height: 100%; } &lt;/style&gt;
&lt;div class=&quot;pdf-embed-wrap-530a5384-04f8-47c2-a9cc-b72807775bec&quot;&gt; &lt;div class=&quot;pdf-link-530a5384-04f8-47c2-a9cc-b72807775bec&quot;&gt; &lt;a href=&quot;/assets/pdfs/2021-05-11-generating-functions-integral-transforms/paper.pdf&quot; target=&quot;_blank&quot;&gt;View PDF&lt;/a&gt; &lt;/div&gt; &lt;div class=&quot;pdf-embed-container-530a5384-04f8-47c2-a9cc-b72807775bec&quot;&gt; &lt;iframe src=&quot;/assets/pdfs/2021-05-11-generating-functions-integral-transforms/paper.pdf&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Stefan Volz</name><email>volzstefan97@googlemail.com</email></author><category term="math" /><category term="generating-functions" /><summary type="html">Ich hatte schon länger eine Korrespondenz zwischen Differentialgleichungen und Rekurrenzgleichungen vermutet. Tatsächlich lassen sich die für Differentialgleichungen wichtigen Integraltransformationen als stetige generierende Funktionen auffassen. Diesen Zusammenhang erläutere ich hier näher.</summary></entry><entry><title type="html">Human Resource Machine XASM</title><link href="https://sv-97.github.io/languages/assembly/rust/python/hrm/" rel="alternate" type="text/html" title="Human Resource Machine XASM" /><published>2019-10-06T00:00:00+00:00</published><updated>2019-10-06T00:00:00+00:00</updated><id>https://sv-97.github.io/languages/assembly/rust/python/hrm</id><content type="html" xml:base="https://sv-97.github.io/languages/assembly/rust/python/hrm/">&lt;p&gt;Ok, so I came across a game called Human Resource Machine last week and blasted through it fairly quickly (I can only recommend it). The game basically is programming a sort of graphical assembly and the sole reason I’m writing about it here is: it supports importing and exporting and exporting source code.&lt;/p&gt;

&lt;h2 id=&quot;instruction-set&quot;&gt;Instruction set&lt;/h2&gt;

&lt;p&gt;The HRM asm has a register based instruction set with only ten instructions:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Inbox&lt;/strong&gt;: Fetch a new input block (an int between -999 and 999 or a char) from the input stream&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Outbox&lt;/strong&gt;: Write your current accumulator to the output stream&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Copyfrom&lt;/strong&gt; rs: Copy to the accumulator from register rs&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Copyto&lt;/strong&gt; rd: Copy the accumulator to register rd&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Add&lt;/strong&gt; rs: Add rs to the accu&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Sub&lt;/strong&gt; rs: Subtract rs from the accu&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Bumpup&lt;/strong&gt; rd: Increment rd and load to accu&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Bumpdn&lt;/strong&gt; rd: Decrement rd and load to accu&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Jump&lt;/strong&gt; m: Jump to m&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Jumpz&lt;/strong&gt; m: Jump to m if accu is zero&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Jumpn&lt;/strong&gt; m: Jump to m if accu is less than zero&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;and also supports pointers (surrrounding a register with brackets makes it a pointer) and single line comments.
Now this is great, but I kinda wanted to do more complicated stuff/ do complicated stuff more easily… so naturally I wrote my own language that offers just slightly more abstraction over HRM’s vanilla language and compiles to native HRM ASM.&lt;/p&gt;

&lt;h2 id=&quot;features-of-xasm&quot;&gt;Features of &lt;em&gt;XASM&lt;/em&gt;&lt;/h2&gt;

&lt;p&gt;My extended asm (I dubbed it &lt;em&gt;XASM&lt;/em&gt;) has a new language feature that allows defining the available amount of memory. You then can easily use variables or essentially named registers without having to worry about their actual adresses - they’re distributed automatically. I didn’t add any new instructions because that would kinda take the fun out of the game.&lt;/p&gt;

&lt;h2 id=&quot;implementation&quot;&gt;Implementation&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/SV-97/HumanResourceMachine&quot;&gt;When it got to implementing the whole thing&lt;/a&gt; I started by writing it in Python which worked great. But when I already had the tokenizer etc. I thought that I might as well think of a bytecode, compile the whole thing and build a VM for it. I started doing this in python but then decided to switch over to Rust which seems to be so much nicer when it comes to building language applications (though I think the new walrus operator coming with Python 3.8 will bring some remedy in that domain). I implemented the following architecture:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/SV-97/HumanResourceMachine/master/architecture.png&quot; alt=&quot;Architecture&quot; /&gt;&lt;/p&gt;

&lt;p&gt;It overall was a fairly straightforward process - I stumbled a bit over the pointers but I had to use 16-bit numbers anyway (With 8-bit jumps - I don’t think anyone will create programs that are over 255 instructions long) for the operands, so I just used one bit of those for the pointer.&lt;/p&gt;

&lt;p&gt;I mapped the original instructions 1:1 to bytecode and wrote a register machine to execute the whole thing.&lt;br /&gt;
Because I wanted to be able to have some color in the output I also implemented a “logging” system with a &lt;em&gt;colored!&lt;/em&gt;-macro that allows applying most of the ANSI-codes to format strings and is also easily extendable via a trait if I did miss something.&lt;br /&gt;
Overall this was a really fun project and great exercise in using Rust - I’m kinda tempted to reimplement it in C or more likely C++, just to see how much more of a pain that would be, but I don’t think I’ll actually do that.&lt;/p&gt;</content><author><name>Stefan Volz</name><email>volzstefan97@googlemail.com</email></author><category term="languages" /><category term="assembly" /><category term="rust" /><category term="python" /><summary type="html">Ok, so I came across a game called Human Resource Machine last week and blasted through it fairly quickly (I can only recommend it). The game basically is programming a sort of graphical assembly and the sole reason I’m writing about it here is: it supports importing and exporting and exporting source code.</summary></entry><entry><title type="html">McCulloch/Pitts neuron model</title><link href="https://sv-97.github.io/soft-computing/math/cs/languages/mcp_neurons/" rel="alternate" type="text/html" title="McCulloch/Pitts neuron model" /><published>2019-05-26T00:00:00+00:00</published><updated>2019-05-26T00:00:00+00:00</updated><id>https://sv-97.github.io/soft-computing/math/cs/languages/mcp_neurons</id><content type="html" xml:base="https://sv-97.github.io/soft-computing/math/cs/languages/mcp_neurons/">&lt;p&gt;So I came across the McCulloch/Pitts (I’ll just call it Mcp) neuron model while reading on ANNs today. The Mcp is a comparatively easy model that doesn’t have a concept of weights. The neurons are of a binary nature. They fire if the sum of their inputs exceed a treshold value (called S in the following). They also have inhibitor inputs that prevent the neuron from firing completely if they’re present.
Naturally I chose to &lt;a href=&quot;https://github.com/SV-97/Py3-Private/tree/master/P3_060_NeuroComputingBasics&quot;&gt;implement it in python&lt;/a&gt; and play around with it.&lt;/p&gt;

&lt;h2 id=&quot;basic-logic&quot;&gt;Basic logic&lt;/h2&gt;

&lt;p&gt;I started off with creating AND and OR gates from the neurons which worked great.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;AND-Gate&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;OR-Gate&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;img src=&quot;/assets/images/2019-05-26-mcp_neurons/mcp_and.png&quot; alt=&quot;AND-Gate&quot; /&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;img src=&quot;/assets/images/2019-05-26-mcp_neurons/mcp_or.png&quot; alt=&quot;OR-Gate&quot; /&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;I just connected normal inputs to the node’s inputs, and negated ones to the inhibition. This fails because that way the treshold value isn’t reached and it can’t possibly fire with the inhibitor being &amp;gt; 0.
While it took me some time to figure this out I was able to quickly adapt to it and create a few more complex gates after I did.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;XOR-Gate&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;NAND-Gate&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;img src=&quot;/assets/images/2019-05-26-mcp_neurons/mcp_xor.png&quot; alt=&quot;XOR-Gate&quot; /&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;img src=&quot;/assets/images/2019-05-26-mcp_neurons/mcp_nand.png&quot; alt=&quot;NAND-Gate&quot; /&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;modelling-dsl&quot;&gt;Modelling DSL&lt;/h2&gt;

&lt;p&gt;After I was done playing around with it I thought that this was a bit short of an “exploration” and constructing the nets by hand like this was too big of a hassle and decided to write a small DSL to automate it.
The language looks like this&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-desc&quot;&gt;title: XOR-Gate using McCulloch-Pitts-Neurons 
in: a b 
out: X 
c: 1 
d: 1 
e: 1 
a -- c 
b -o c 
a -o d 
b -- d 
d -- e 
c -- e 
e -- X
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Which of course is fairly minimalistic but enough for what I wanted to do here. It also transpiles to graphviz-dot to generate these graphs I’ve had in here. The language essentially comes down to declaring inputs with “in:”, outputs with “out:”, internal neurons with their name followed by their treshold and connections with  “–” for regular links and “-o” for inhibitions.
I’ve also tried using regular expressions for parsing which was a first but worked out fairly well ( even though the code isn’t exactly beautiful ).&lt;/p&gt;

&lt;p&gt;Just for the fun of it I also built a two bit half-adder using these neurons and I haven’t tested it yet, but I think it works (In case anyone is interested: it took about 50 lines of my descriptor-code).&lt;/p&gt;

&lt;h2 id=&quot;two-bit-half-adder&quot;&gt;Two-Bit-Half-Adder&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/2019-05-26-mcp_neurons/mcp_adder.png&quot; alt=&quot;Two-Bit-Half-Adder&quot; /&gt;&lt;/p&gt;</content><author><name>Stefan Volz</name><email>volzstefan97@googlemail.com</email></author><category term="soft-computing" /><category term="math" /><category term="CS" /><category term="languages" /><summary type="html">So I came across the McCulloch/Pitts (I’ll just call it Mcp) neuron model while reading on ANNs today. The Mcp is a comparatively easy model that doesn’t have a concept of weights. The neurons are of a binary nature. They fire if the sum of their inputs exceed a treshold value (called S in the following). They also have inhibitor inputs that prevent the neuron from firing completely if they’re present. Naturally I chose to implement it in python and play around with it.</summary></entry></feed>